{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO**\n",
    "\n",
    "https://towardsdatascience.com/exploratory-data-analysis-for-natural-language-processing-ff0046ab3571\n",
    "\n",
    "https://marcobonzanini.com/2015/03/09/mining-twitter-data-with-python-part-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Load-Packages\" data-toc-modified-id=\"Load-Packages-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Packages</a></span></li><li><span><a href=\"#Load-Cleaned-Data\" data-toc-modified-id=\"Load-Cleaned-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load Cleaned Data</a></span></li><li><span><a href=\"#EDA\" data-toc-modified-id=\"EDA-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>EDA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Number-of-followers-and-friends\" data-toc-modified-id=\"Number-of-followers-and-friends-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Number of followers and friends</a></span></li><li><span><a href=\"#Languages-of-messages\" data-toc-modified-id=\"Languages-of-messages-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Languages of messages</a></span></li></ul></li><li><span><a href=\"#Analysing-Queries\" data-toc-modified-id=\"Analysing-Queries-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Analysing Queries</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-query-data\" data-toc-modified-id=\"Load-query-data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Load query data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO ADAPT AND INSERT SOMEWHERE**\n",
    "\n",
    "attributes are the following:\n",
    "\n",
    "text: the text of the tweet itself\n",
    "\n",
    "created_at: the date of creation\n",
    "\n",
    "favorite_count, retweet_count: the number of favourites and retweets\n",
    "\n",
    "favorited, retweeted: boolean stating whether the authenticated user (you) have favourited or retweeted this tweet\n",
    "\n",
    "lang: acronym for the language (e.g. “en” for english)\n",
    "\n",
    "id: the tweet identifier\n",
    "\n",
    "We can imagine how these data already allow for some interesting analysis: we can check who is most favourited/retweeted, who’s discussing with who, what are the most popular hashtags and so on. Most of the goodness we’re looking for, i.e. the content of a tweet, is anyway embedded in the text, and that’s where we’re starting our analysis.\n",
    "\n",
    "**MY GOAL**\n",
    "\n",
    "1. Cleaning\n",
    "    Clean text without tokenize (at least no using a tokenizer) neither remove stop words.\n",
    "    \n",
    "    Complement my function checking :\n",
    "    \n",
    "    http://localhost:8889/notebooks/Project_Twitter/planing%20twitter%20project.ipynb\n",
    "    \n",
    "    https://marcobonzanini.com/2015/03/09/mining-twitter-data-with-python-part-2/\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "and create 2 columns:\n",
    "\n",
    "sentiment_score: \n",
    "\n",
    "sentiment: neg (<0), pos (>0), neutral (0)\n",
    "\n",
    "In some vizualizations groupby supermarkt, sentiment and then:\n",
    "\n",
    "- check most frequent words : pos and negative\n",
    "- check timeline of the 3 supermarkts pos and neg\n",
    "- Build Word Cloud using mask (tokenize and remove stop words)\n",
    "\n",
    "- tokenize using split() - dividing by space and use the dutch stopwords because \n",
    "\"It must be trained on a large collection of plaintext in the target language before it can be used.\" https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The goal here is to perform some EDA and Sentiment Analysis to infer how user of online supermarkets feel towards these supermarkets in the period from March 30th, 2020 and June 24th, 2020. This period does not cover all period considering the 1st corona case in The Netherlands (February 27th) but as seen in the following graph still covers an important period of the crisis.\n",
    "\n",
    "![corona cases from 27022020 until 25062020](../images/graph_corona_cases_nl_270220_250620.jpg)\n",
    "source: https://www.rivm.nl/coronavirus-covid-19/grafieken\n",
    "\n",
    "Our analysis separated in two parts:\n",
    "\n",
    "1. **[User timeline data](#User-Timeline-Tweet-Data)** \n",
    "2. Search data\n",
    "\n",
    "The following actions are taken in order to achieve our goal.\n",
    "\n",
    "1. **[Load data](#Load-User-Timeline-Data)**\n",
    "2. **[Select interesting features for our analysis](#Pre-processing)**\n",
    "3. **[Concatenate data](#Concatenating-Data-within-period-March-30th-and-June-24th)**\n",
    "4. **Perform analysis over languages present in our data and decide how to deal with it**\n",
    "5. **Clean text for sentiment analysis**\n",
    "6. **Create features that measure sentiment**\n",
    "7. **Perform EDA and Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Concatenating Data within period March 30th and June 24th\".replace(\" \",\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "TodaysDate = time.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all dataframes\n",
    "\n",
    "df_tweet_conc = pd.concat([df_picnic,df_JumboSupermarkt, df_albertheijn])\n",
    "df_tweet_conc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_conc.shape[0] == df_picnic.shape[0]+df_JumboSupermarkt.shape[0]+df_albertheijn.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of followers and friends "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Languages of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Queries\n",
    "\n",
    "## Load query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
