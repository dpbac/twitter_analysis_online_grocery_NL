{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'private_twitter_credentials' contains my Twitter credentials. Replace by 'twitter_credentials' with your credentials\n",
    "import private_twitter_credentials\n",
    "import twitter\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "TodaysDate = time.strftime(\"%Y-%m-%d-%H-%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeting up twitter authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = private_twitter_credentials.consumer_key\n",
    "consumer_secret = private_twitter_credentials.consumer_secret\n",
    "access_token = private_twitter_credentials.access_token\n",
    "access_token_secret = private_twitter_credentials.access_token_secret\n",
    "\n",
    "api = twitter.Api(\n",
    "    consumer_key         =   consumer_key,\n",
    "    consumer_secret      =   consumer_secret,\n",
    "    access_token_key     =   access_token,\n",
    "    access_token_secret  =   access_token_secret,\n",
    "    tweet_mode = 'extended'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "Class `TweetMiner` class contains two methods: \n",
    "\n",
    "* `mine_user_tweets` which mine user's tweets making use of [Get user_timeline](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline)\n",
    "\n",
    "* `search_tweets` which mine tweets using [GetSearch](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets)\n",
    "\n",
    "`search_tweets` gives you possibility to perform queries. You can for instances perform a search at Twitter and copy what comes after `q` in your browser.\n",
    "\n",
    "For example, if I search `@picnic @JumboSupermarkt @albertheijn covid-19` the query used as argument in `search_tweets` is `q=%40picnic%20%40JumboSupermarkt%20%40albertheijn%20covid-19&src=typed_query`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T07:34:34.325020Z",
     "start_time": "2019-05-06T07:34:34.299182Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class TweetMiner(object):\n",
    "    \"\"\" Make possible obtaining tweets using twitter user id (mine_user_tweets) or performing a standard Twitter \n",
    "    API search\"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, api, result_limit = 20, max_pages = 40):\n",
    "        \"\"\"result_limit = count that can take max 200 (mine_user_tweets) and max 100 (search_tweets)\"\"\"\n",
    "        \n",
    "        self.api = api        \n",
    "        self.result_limit = result_limit\n",
    "        self.max_pages = max_pages\n",
    "        \n",
    "\n",
    "    def mine_user_tweets(self, user, mine_retweets=False):\n",
    "        \"\"\" Mine tweets of user = screen_name or user_id\"\"\"\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= self.max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, max_id=last_tweet_id - 1, \n",
    "                                                        include_rts=mine_retweets)\n",
    "                statuses = [ _.AsDict() for _ in statuses]\n",
    "            else:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, \n",
    "                                                        include_rts=mine_retweets)\n",
    "                statuses = [_.AsDict() for _ in statuses]\n",
    "                \n",
    "            for item in statuses:\n",
    "                # Using try except here.\n",
    "                # When retweets = 0 we get an error (GetUserTimeline fails to create a key, 'retweet_count')\n",
    "                try:\n",
    "                    mined = {\n",
    "                        'mined_at':         datetime.datetime.now(),\n",
    "                        'created_at':       item['created_at'],\n",
    "                        'tweet_id':         item['id'],\n",
    "                        'tweet_id_str':     item['id_str'],\n",
    "                        'screen_name':      item['user']['screen_name'],\n",
    "                        'favorite_count':   item['favorite_count'],\n",
    "                        'text':             item['full_text'],\n",
    "                        'source':           item['source'],\n",
    "                        'language':         item['lang'],\n",
    "                        'retweet_count':    item['retweet_count'],\n",
    "                        #user info\n",
    "                        'user_favourites_count': item['user']['favourites_count'],\n",
    "                        'followers_count':  item['user']['followers_count'],\n",
    "                        'friends_count':    item['user']['friends_count']\n",
    "                    }\n",
    "            \n",
    "                \n",
    "                except:\n",
    "                    mined = {\n",
    "                        'mined_at':         datetime.datetime.now(),\n",
    "                        'created_at':       item['created_at'],\n",
    "                        'tweet_id':         item['id'],\n",
    "                        'tweet_id_str':     item['id_str'],\n",
    "                        'screen_name':      item['user']['screen_name'],\n",
    "#                         'favorite_count':   item['favorite_count'],\n",
    "                        'text':             item['full_text'],\n",
    "                        'source':           item['source'],\n",
    "                        'language':         item['lang'],\n",
    "                        'retweet_count':    0,\n",
    "                        # user info\n",
    "                        'user_favourites_count': item['user']['favourites_count'],\n",
    "                        'followers_count':  item['user']['followers_count'],\n",
    "                        'friends_count':    item['user']['friends_count']\n",
    "                        }\n",
    "                \n",
    "                last_tweet_id = item['id']\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def search_tweets(max_pages = 20, count = 20, raw_query = None, result_type = 'mixed'):\n",
    "        \"\"\" Search tweets \"\"\"\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses = api.GetSearch(raw_query=raw_query, count = count, result_type=result_type, \n",
    "                                         max_id=last_tweet_id - 1)\n",
    "                statuses = [ _.AsDict() for _ in statuses]\n",
    "            else:\n",
    "                statuses = api.GetSearch(raw_query=raw_query, count = count, result_type=result_type)\n",
    "                statuses = [_.AsDict() for _ in statuses]\n",
    "                \n",
    "            for item in statuses:\n",
    "                # Using try except here.\n",
    "                # When retweets = 0 we get an error (GetUserTimeline fails to create a key, 'retweet_count')\n",
    "                try:\n",
    "                    mined = {\n",
    "                        'mined_at':                datetime.datetime.now(),\n",
    "                        'created_at':              item['created_at'],\n",
    "                        'tweet_id':                item['id'],\n",
    "                        'tweet_id_str':            item['id_str'],\n",
    "                        'in_reply_to_screen_name': item['in_reply_to_screen_name'],\n",
    "                        'in_reply_to_status_id':   item['in_reply_to_status_id'],\n",
    "                        'in_reply_to_user_id':     item['in_reply_to_user_id'],\n",
    "                        'language':                item['lang'],\n",
    "                        'text':                    item['full_text'],\n",
    "                        'hashtags':                item['hashtags'],\n",
    "                        'source':                  item['source'],\n",
    "                       # info about user\n",
    "                        'screen_name':             item['user']['screen_name'],\n",
    "                        'user_tweet_id':           item['user']['id'],\n",
    "                        'user_tweet_id_str':       item['user']['id_str'],\n",
    "                        'user_favourites_count':   item['user']['favourites_count'],\n",
    "                        'followers_count':         item['user']['followers_count'],\n",
    "                        'friends_count':           item['user']['friends_count']\n",
    "                    }\n",
    "                    \n",
    "                except:\n",
    "                    mined = {\n",
    "                        'mined_at':                datetime.datetime.now(),\n",
    "                        'created_at':              item['created_at'],\n",
    "                        'tweet_id':                item['id'],\n",
    "                        'tweet_id_str':            item['id_str'],\n",
    "#                         'in_reply_to_screen_name': item['in_reply_to_screen_name'],\n",
    "#                         'in_reply_to_status_id':   item['in_reply_to_status_id'],\n",
    "#                         'in_reply_to_user_id':     item['in_reply_to_user_id'],\n",
    "                        'language':                item['lang'],\n",
    "                        'text':                    item['full_text'],\n",
    "                        'hashtags':                item['hashtags'],\n",
    "                        'source':                  item['source'],\n",
    "                       # info about user\n",
    "                        'screen_name':             item['user']['screen_name'],\n",
    "                        'user_tweet_id':           item['user']['id'],\n",
    "                        'user_tweet_id_str':       item['user']['id_str'],\n",
    "                        'user_favourites_count':   item['user']['favourites_count'],\n",
    "                        'followers_count':         item['user']['followers_count'],\n",
    "                        'friends_count':           item['user']['friends_count']\n",
    "                    }\n",
    "                                            \n",
    "                \n",
    "                last_tweet_id = item['id']\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T07:34:34.346271Z",
     "start_time": "2019-05-06T07:34:34.330962Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_and_save(df, file_name, mine_user_twitter=1):\n",
    "    \"\"\" Save retrieved tweets in csv file.\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    df : dataframe of tweets'data\n",
    "    file_name: name with which the csv will be saved (without extension)\n",
    "    mine_user_twitter: Indicates if df came contains tweets from a twitter user, i.e., was obtained using \n",
    "    GetUserTimeline since the information obtained from this method is different from an API search from GetSearch\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    TodaysDate = time.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "    \n",
    "    # Create columns 'year', 'month', 'day', 'hour', 'min' from 'created_at'\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "        \n",
    "    df['year'] = df['created_at'].dt.year \n",
    "    df['month'] = df['created_at'].dt.month \n",
    "    df['day'] = df['created_at'].dt.day \n",
    "    df['hour'] = df['created_at'].dt.hour \n",
    "    df['minute'] = df['created_at'].dt.minute\n",
    "    df['day_of_week'] = df['created_at'].dt.weekday\n",
    "    \n",
    "    if mine_user_twitter:\n",
    "    \n",
    "        df = df[['mined_at', 'created_at', 'year', 'month', 'day','day_of_week', \n",
    "             'hour', 'minute', 'screen_name', 'tweet_id', 'tweet_id_str',  'retweet_count', 'favorite_count', 'source', 'language', 'user_favourites_count', \n",
    "             'followers_count','friends_count','text']]\n",
    "    else:\n",
    "        df = df[['mined_at','created_at', 'year', 'month', 'day','day_of_week', \n",
    "                 'hour', 'minute', 'tweet_id', 'tweet_id_str', 'in_reply_to_screen_name','in_reply_to_status_id',\n",
    "                 'in_reply_to_user_id', 'hashtags','source','language', 'screen_name','user_tweet_id','user_tweet_id_str','user_favourites_count','followers_count',\n",
    "                 'friends_count', 'text']]\n",
    "        \n",
    "    df.sort_values(by='created_at',inplace = True)\n",
    "    df = df.loc[df.astype(str).drop_duplicates(subset=['created_at','tweet_id','text']).index]\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    df.to_csv(\"../data/tweets/\"+file_name+\"_\"+TodaysDate+\".csv\", index = False)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving twitter data\n",
    "\n",
    "The goal of this project is to check the sentiment of users towards the main providers of online grocery shopping, i.e., Jumbo Supermarkten, AH, and Picnic.\n",
    "\n",
    "Everything changed since the first case of corona virus in The Netherlands (February 27th) and the way of shopping groceries suffered important change with a jump in number of users that opted for online grocery shopping. Supermarkts were not ready for such a explosion of demand, some adapted faster than others. Specially, `Picnic` that has the sole focus on online shopping.\n",
    "\n",
    "I have my own experiences but I want to via tweets messages over these 3 providers of online grocery shopping get the sentiment of the users in this 'special' moments faced by both consumers and providers.\n",
    "\n",
    "The idea is to get twitters covering the period from the 1st case until today both for info retrieved by user (`GetUserTimeline`) and by query (`GetSearch`).\n",
    "\n",
    "Although, it is not possible to have control over the period covered by the search, we will play with parameters and go as far as possible.\n",
    "\n",
    "## Getting twitter by user\n",
    "\n",
    "To start we will obtain tweets for `picnic`, `JumboSupermarkt`, and `albertheijn` which are the tweet screen name of the 3 providers of online grocery shopping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picnic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=20, max_pages = 100)\n",
    "picnic = miner.mine_user_tweets(user=\"picnic\")\n",
    "df_picnic = process_and_save(pd.DataFrame(picnic), \"picnic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mined_at</th>\n",
       "      <th>created_at</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>2020-06-21 13:16:24.115881</td>\n",
       "      <td>2020-06-18 17:04:24+00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>picnic</td>\n",
       "      <td>1273662862096060417</td>\n",
       "      <td>1273662862096060417</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://www.zendesk.com\" rel=\"nofollow...</td>\n",
       "      <td>nl</td>\n",
       "      <td>3881</td>\n",
       "      <td>4843</td>\n",
       "      <td>5</td>\n",
       "      <td>@rolandweyers Ah, dat is inderdaad een dode mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>2020-06-21 13:16:24.115881</td>\n",
       "      <td>2020-06-19 09:59:09+00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>picnic</td>\n",
       "      <td>1273918233834393602</td>\n",
       "      <td>1273918233834393602</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>nl</td>\n",
       "      <td>3881</td>\n",
       "      <td>4843</td>\n",
       "      <td>5</td>\n",
       "      <td>@MiriamVermeulen Wat fijn dat je al 100 plekke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>2020-06-21 13:16:24.115881</td>\n",
       "      <td>2020-06-19 10:09:21+00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>picnic</td>\n",
       "      <td>1273920800064757760</td>\n",
       "      <td>1273920800064757760</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>nl</td>\n",
       "      <td>3881</td>\n",
       "      <td>4843</td>\n",
       "      <td>5</td>\n",
       "      <td>@MrsVlamingo De Presto maaltijden variëren af ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>2020-06-21 13:16:24.115881</td>\n",
       "      <td>2020-06-20 09:40:19+00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>picnic</td>\n",
       "      <td>1274275880756482049</td>\n",
       "      <td>1274275880756482049</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://www.zendesk.com\" rel=\"nofollow...</td>\n",
       "      <td>nl</td>\n",
       "      <td>3881</td>\n",
       "      <td>4843</td>\n",
       "      <td>5</td>\n",
       "      <td>@Mr_Widewood Goedemorgen! Goed dat je dit even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>2020-06-21 13:16:24.115881</td>\n",
       "      <td>2020-06-20 19:56:51+00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>picnic</td>\n",
       "      <td>1274431035896467466</td>\n",
       "      <td>1274431035896467466</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>es</td>\n",
       "      <td>3881</td>\n",
       "      <td>4843</td>\n",
       "      <td>5</td>\n",
       "      <td>@dbenshachar ^Lino https://t.co/XK06YZyXVh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mined_at                created_at  year  month  day  \\\n",
       "1990 2020-06-21 13:16:24.115881 2020-06-18 17:04:24+00:00  2020      6   18   \n",
       "1991 2020-06-21 13:16:24.115881 2020-06-19 09:59:09+00:00  2020      6   19   \n",
       "1992 2020-06-21 13:16:24.115881 2020-06-19 10:09:21+00:00  2020      6   19   \n",
       "1993 2020-06-21 13:16:24.115881 2020-06-20 09:40:19+00:00  2020      6   20   \n",
       "1994 2020-06-21 13:16:24.115881 2020-06-20 19:56:51+00:00  2020      6   20   \n",
       "\n",
       "      day_of_week  hour  minute screen_name             tweet_id  \\\n",
       "1990            3    17       4      picnic  1273662862096060417   \n",
       "1991            4     9      59      picnic  1273918233834393602   \n",
       "1992            4    10       9      picnic  1273920800064757760   \n",
       "1993            5     9      40      picnic  1274275880756482049   \n",
       "1994            5    19      56      picnic  1274431035896467466   \n",
       "\n",
       "             tweet_id_str  retweet_count  favorite_count  \\\n",
       "1990  1273662862096060417              0             NaN   \n",
       "1991  1273918233834393602              0             NaN   \n",
       "1992  1273920800064757760              0             NaN   \n",
       "1993  1274275880756482049              0             NaN   \n",
       "1994  1274431035896467466              0             NaN   \n",
       "\n",
       "                                                 source language  \\\n",
       "1990  <a href=\"http://www.zendesk.com\" rel=\"nofollow...       nl   \n",
       "1991  <a href=\"https://mobile.twitter.com\" rel=\"nofo...       nl   \n",
       "1992  <a href=\"https://mobile.twitter.com\" rel=\"nofo...       nl   \n",
       "1993  <a href=\"http://www.zendesk.com\" rel=\"nofollow...       nl   \n",
       "1994  <a href=\"https://mobile.twitter.com\" rel=\"nofo...       es   \n",
       "\n",
       "      user_favourites_count  followers_count  friends_count  \\\n",
       "1990                   3881             4843              5   \n",
       "1991                   3881             4843              5   \n",
       "1992                   3881             4843              5   \n",
       "1993                   3881             4843              5   \n",
       "1994                   3881             4843              5   \n",
       "\n",
       "                                                   text  \n",
       "1990  @rolandweyers Ah, dat is inderdaad een dode mu...  \n",
       "1991  @MiriamVermeulen Wat fijn dat je al 100 plekke...  \n",
       "1992  @MrsVlamingo De Presto maaltijden variëren af ...  \n",
       "1993  @Mr_Widewood Goedemorgen! Goed dat je dit even...  \n",
       "1994         @dbenshachar ^Lino https://t.co/XK06YZyXVh  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_picnic.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1995 entries, 0 to 1994\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype              \n",
      "---  ------                 --------------  -----              \n",
      " 0   mined_at               1995 non-null   datetime64[ns]     \n",
      " 1   created_at             1995 non-null   datetime64[ns, UTC]\n",
      " 2   year                   1995 non-null   int64              \n",
      " 3   month                  1995 non-null   int64              \n",
      " 4   day                    1995 non-null   int64              \n",
      " 5   day_of_week            1995 non-null   int64              \n",
      " 6   hour                   1995 non-null   int64              \n",
      " 7   minute                 1995 non-null   int64              \n",
      " 8   screen_name            1995 non-null   object             \n",
      " 9   tweet_id               1995 non-null   int64              \n",
      " 10  tweet_id_str           1995 non-null   object             \n",
      " 11  retweet_count          1995 non-null   int64              \n",
      " 12  favorite_count         28 non-null     float64            \n",
      " 13  source                 1995 non-null   object             \n",
      " 14  language               1995 non-null   object             \n",
      " 15  user_favourites_count  1995 non-null   int64              \n",
      " 16  followers_count        1995 non-null   int64              \n",
      " 17  friends_count          1995 non-null   int64              \n",
      " 18  text                   1995 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), float64(1), int64(11), object(5)\n",
      "memory usage: 296.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_picnic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-07-13 18:42:42+0000', tz='UTC'),\n",
       " Timestamp('2020-06-20 19:56:51+0000', tz='UTC'))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_picnic.created_at),max(df_picnic.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `Picnic` we went far enough. We got data back to July 2019!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picnic's followers 4843\n",
      "Picnic's friends 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Picnic's followers\", df_picnic.loc[df_picnic.shape[0]-1,'followers_count'])\n",
    "print(\"Picnic's friends\", df_picnic.loc[df_picnic.shape[0]-1,'friends_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nl     1780\n",
       "und     145\n",
       "en       53\n",
       "es        5\n",
       "de        3\n",
       "in        2\n",
       "fr        2\n",
       "it        1\n",
       "ht        1\n",
       "cy        1\n",
       "sv        1\n",
       "fi        1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_picnic['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JumboSupermarkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=20, max_pages = 200)\n",
    "JumboSupermarkt = miner.mine_user_tweets(user=\"JumboSupermarkt\")\n",
    "df_JumboSupermarkt = processing_and_saving(pd.DataFrame(JumboSupermarkt), \"JumboSupermarkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3230 entries, 0 to 3229\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype              \n",
      "---  ------                 --------------  -----              \n",
      " 0   mined_at               3230 non-null   datetime64[ns]     \n",
      " 1   created_at             3230 non-null   datetime64[ns, UTC]\n",
      " 2   year                   3230 non-null   int64              \n",
      " 3   month                  3230 non-null   int64              \n",
      " 4   day                    3230 non-null   int64              \n",
      " 5   day_of_week            3230 non-null   int64              \n",
      " 6   hour                   3230 non-null   int64              \n",
      " 7   minute                 3230 non-null   int64              \n",
      " 8   screen_name            3230 non-null   object             \n",
      " 9   tweet_id               3230 non-null   int64              \n",
      " 10  tweet_id_str           3230 non-null   object             \n",
      " 11  retweet_count          3230 non-null   int64              \n",
      " 12  favorite_count         13 non-null     float64            \n",
      " 13  source                 3230 non-null   object             \n",
      " 14  language               3230 non-null   object             \n",
      " 15  user_favourites_count  3230 non-null   int64              \n",
      " 16  followers_count        3230 non-null   int64              \n",
      " 17  friends_count          3230 non-null   int64              \n",
      " 18  text                   3230 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), float64(1), int64(11), object(5)\n",
      "memory usage: 479.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_JumboSupermarkt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2020-03-06 19:12:05+0000', tz='UTC'),\n",
       " Timestamp('2020-06-21 09:33:32+0000', tz='UTC'))"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_JumboSupermarkt.created_at),max(df_JumboSupermarkt.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=25, max_pages = 250)\n",
    "JumboSupermarkt = miner.mine_user_tweets(user=\"JumboSupermarkt\")\n",
    "df_JumboSupermarkt = process_and_save(pd.DataFrame(JumboSupermarkt), \"JumboSupermarkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2020-03-07 20:15:43+0000', tz='UTC'),\n",
       " Timestamp('2020-06-21 09:33:32+0000', tz='UTC'))"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_JumboSupermarkt.created_at),max(df_JumboSupermarkt.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing parameters does not seem to help here and we could only retrieve data from March 6th, 2020 until now for Jumbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumbo's followers 16212\n",
      "Jumbo's friends 1710\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumbo's followers\", df_JumboSupermarkt.loc[df_JumboSupermarkt.shape[0]-1,'followers_count'])\n",
    "print(\"Jumbo's friends\", df_JumboSupermarkt.loc[df_JumboSupermarkt.shape[0]-1,'friends_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nl     3112\n",
       "en       68\n",
       "und      25\n",
       "in        3\n",
       "de        2\n",
       "da        1\n",
       "tl        1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_JumboSupermarkt['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albertheijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=200, max_pages = 20)\n",
    "albertheijn = miner.mine_user_tweets(user=\"albertheijn\")\n",
    "df_albertheijn = process_and_save(pd.DataFrame(albertheijn), \"albertheijn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3218 entries, 0 to 3217\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype              \n",
      "---  ------                 --------------  -----              \n",
      " 0   mined_at               3218 non-null   datetime64[ns]     \n",
      " 1   created_at             3218 non-null   datetime64[ns, UTC]\n",
      " 2   year                   3218 non-null   int64              \n",
      " 3   month                  3218 non-null   int64              \n",
      " 4   day                    3218 non-null   int64              \n",
      " 5   day_of_week            3218 non-null   int64              \n",
      " 6   hour                   3218 non-null   int64              \n",
      " 7   minute                 3218 non-null   int64              \n",
      " 8   screen_name            3218 non-null   object             \n",
      " 9   tweet_id               3218 non-null   int64              \n",
      " 10  tweet_id_str           3218 non-null   object             \n",
      " 11  retweet_count          3218 non-null   int64              \n",
      " 12  favorite_count         24 non-null     float64            \n",
      " 13  source                 3218 non-null   object             \n",
      " 14  language               3218 non-null   object             \n",
      " 15  user_favourites_count  3218 non-null   int64              \n",
      " 16  followers_count        3218 non-null   int64              \n",
      " 17  friends_count          3218 non-null   int64              \n",
      " 18  text                   3218 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), float64(1), int64(11), object(5)\n",
      "memory usage: 477.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_albertheijn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2020-04-03 15:35:47+0000', tz='UTC'),\n",
       " Timestamp('2020-06-21 12:27:32+0000', tz='UTC'))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_albertheijn.created_at),max(df_albertheijn.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=200, max_pages = 100)\n",
    "albertheijn = miner.mine_user_tweets(user=\"albertheijn\")\n",
    "df_albertheijn = process_and_save(pd.DataFrame(albertheijn), \"albertheijn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2020-04-03 15:35:47+0000', tz='UTC'),\n",
       " Timestamp('2020-06-21 12:45:16+0000', tz='UTC'))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_albertheijn.created_at),max(df_albertheijn.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3219 entries, 0 to 3218\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype              \n",
      "---  ------                 --------------  -----              \n",
      " 0   mined_at               3219 non-null   datetime64[ns]     \n",
      " 1   created_at             3219 non-null   datetime64[ns, UTC]\n",
      " 2   year                   3219 non-null   int64              \n",
      " 3   month                  3219 non-null   int64              \n",
      " 4   day                    3219 non-null   int64              \n",
      " 5   day_of_week            3219 non-null   int64              \n",
      " 6   hour                   3219 non-null   int64              \n",
      " 7   minute                 3219 non-null   int64              \n",
      " 8   screen_name            3219 non-null   object             \n",
      " 9   tweet_id               3219 non-null   int64              \n",
      " 10  tweet_id_str           3219 non-null   object             \n",
      " 11  retweet_count          3219 non-null   int64              \n",
      " 12  favorite_count         24 non-null     float64            \n",
      " 13  source                 3219 non-null   object             \n",
      " 14  language               3219 non-null   object             \n",
      " 15  user_favourites_count  3219 non-null   int64              \n",
      " 16  followers_count        3219 non-null   int64              \n",
      " 17  friends_count          3219 non-null   int64              \n",
      " 18  text                   3219 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), float64(1), int64(11), object(5)\n",
      "memory usage: 477.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_albertheijn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the changing parameters didn't work. For `AH` we only succeeded in getting back to April 3th, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AH's followers 45523\n",
      "AH's friends 5\n"
     ]
    }
   ],
   "source": [
    "print(\"AH's followers\", df_albertheijn.loc[df_albertheijn.shape[0]-1,'followers_count'])\n",
    "print(\"AH's friends\", df_albertheijn.loc[df_albertheijn.shape[0]-1,'friends_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nl     3111\n",
       "en       74\n",
       "und       7\n",
       "et        5\n",
       "fr        5\n",
       "tr        4\n",
       "fi        3\n",
       "in        2\n",
       "da        2\n",
       "pl        1\n",
       "de        1\n",
       "is        1\n",
       "ht        1\n",
       "sv        1\n",
       "es        1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_albertheijn['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying GetSearch to search for a defined query\n",
    "\n",
    "\n",
    "Twitter’s search parameters are a bit complex, to perform a particular search, you can consult Twitter’s documentation at https://dev.twitter.com/rest/public/search.\n",
    "\n",
    "An easier way is to make use of [Twitter’s Advanced Search](toolhttps://twitter.com/search-advanced), and then use the part of search URL after the \"?\" to use `raw_query`, removing the `&src=typd` portion.\n",
    "\n",
    "In this section we will perform some queries to allow us to compare `Picnic`, `Jumbo`, and `AH`. In particular, my main goal is to include also `COVID-19`. But since we are in June and things seem to be now much more in control than few months ago I'm not sure if I'll be able to retrieve enough Tweets using these key words.\n",
    "\n",
    "In addition, the results obtained from Twitter API searches against a sampling of recent Tweets published in the past 7 days (more details [here](https://developer.twitter.com/en/docs/tweets/search/overview/standard). So the results you see in the website when using `Twitter’s Advanced Search` will not per se be in the result of the API search. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query_01:\n",
    "\n",
    "`All these words`: picnic, jumbo, ah, covid\n",
    "\n",
    "`Dates:`\n",
    "\n",
    "    From: February - 25 -2020\n",
    "    To:   June - 21 -2020\n",
    "\n",
    "**Result:** `https://twitter.com/search?q=picnic%2C%20jumbo%2C%20ah%2C%20covid%20until%3A2020-06-21%20since%3A2020-02-25&src=typed_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_01 = 'q=picnic%2C%20jumbo%2C%20ah%2C%20covid%20until%3A2020-06-21%20since%3A2020-02-25'\n",
    "result = TweetMiner.search_tweets(raw_query = query_01)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected, since the 2 Tweets there are from March and therefore will not be catch by the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query_02:\n",
    "\n",
    "So let's make a query without `covid`.\n",
    "\n",
    "`All these words`: picnic, jumbo, ah\n",
    "\n",
    "**Result:** `https://twitter.com/search?q=picnic%2C%20jumbo%2C%20ah&src=typed_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_02 = 'q=picnic%2C%20jumbo%2C%20ah'\n",
    "result_02 = TweetMiner.search_tweets(max_pages = 20, count = 100, raw_query = query_02)\n",
    "len(result_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_02[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_query_02 = process_and_save(pd.DataFrame(result_02),\"query_02\",mine_user_twitter=0)\n",
    "df_query_02.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_02.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query_03:\n",
    "\n",
    "Adding `albertheijn` because sometimes there are expressions like `ahhhhh` and this is not what we are looking for.\n",
    "\n",
    "`All these words`: picnic, jumbo, ah, albertheijn\n",
    "\n",
    "**Result:** `https://twitter.com/search?q=picnic%2C%20jumbo%2C%20ah%2C%20albertheijn&src=typed_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_03 = 'q=picnic%2C%20jumbo%2C%20ah%2C%20albertheijn'\n",
    "result_03 = TweetMiner.search_tweets(max_pages = 20, raw_query = query_03)\n",
    "len(result_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_03[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_query_03 = process_and_save(pd.DataFrame(result_03),\"query_03\",mine_user_twitter=0)\n",
    "df_query_03.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_03.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query_04:\n",
    "\n",
    "`All these words`: picnic covid\n",
    "\n",
    "**Result:** `https://twitter.com/search?q=picnic%20covid&src=typed_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_04 = 'q=picnic%20covid'\n",
    "result_04 = TweetMiner.search_tweets(max_pages = 20, raw_query = query_04)\n",
    "len(result_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_04[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_query_04 = process_and_save(pd.DataFrame(result_04),\"query_04\",mine_user_twitter=0)\n",
    "df_query_04.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_04.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query_05:\n",
    "\n",
    "`All these words`: JumboSupermarkt covid\n",
    "\n",
    "**Result:** `https://twitter.com/search?q=JumboSupermarkt%20covid&src=typed_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_05 = 'q=JumboSupermarkt%20covid'\n",
    "result_05 = TweetMiner.search_tweets(max_pages = 20, raw_query = query_05)\n",
    "len(result_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_05[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_query_05 = process_and_save(pd.DataFrame(result_05),\"query_05\",mine_user_twitter=0)\n",
    "df_query_05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_05.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query_06:\n",
    "\n",
    "`All these words`: albertheijn covid ah\n",
    "\n",
    "**Result:** `https://twitter.com/search?q=albertheijn%20covid&src=typed_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_06 = 'q=albertheijn%20covid'\n",
    "result_06 = TweetMiner.search_tweets(max_pages = 20, raw_query = query_06)\n",
    "len(result_06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_06[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_query_06 = process_and_save(pd.DataFrame(result_06),\"query_06\",mine_user_twitter=0)\n",
    "df_query_06.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_06.info()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
