{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'private_twitter_credentials' contains my Twitter credentials. Replace by 'twitter_credentials' with your credentials\n",
    "import private_twitter_credentials\n",
    "import twitter\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "TodaysDate = time.strftime(\"%Y-%m-%d-%H-%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeting up twitter authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = private_twitter_credentials.consumer_key\n",
    "consumer_secret = private_twitter_credentials.consumer_secret\n",
    "access_token = private_twitter_credentials.access_token\n",
    "access_token_secret = private_twitter_credentials.access_token_secret\n",
    "\n",
    "api = twitter.Api(\n",
    "    consumer_key         =   consumer_key,\n",
    "    consumer_secret      =   consumer_secret,\n",
    "    access_token_key     =   access_token,\n",
    "    access_token_secret  =   access_token_secret,\n",
    "    tweet_mode = 'extended'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "Class `TweetMiner` class contains two methods: \n",
    "\n",
    "* `mine_user_tweets` which mine user's tweets making use of [Get user_timeline](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline)\n",
    "\n",
    "* `search_tweets` which mine tweets using [GetSearch](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets)\n",
    "\n",
    "`search_tweets` gives you possibility to perform queries. You can for instances perform a search at Twitter and copy what comes after `q` in your browser.\n",
    "\n",
    "For example, if I search `@picnic @JumboSupermarkt @albertheijn covid-19` I have after `q` : `%40picnic%20%40JumboSupermarkt%20%40albertheijn%20covid-19&src=typed_query`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T07:34:34.325020Z",
     "start_time": "2019-05-06T07:34:34.299182Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class TweetMiner(object):\n",
    "    \"\"\" Make possible obtaining tweets using twitter user id (mine_user_tweets) or performing a standard Twitter \n",
    "    API search\"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, api, result_limit = 20, max_pages = 40):\n",
    "        \"\"\"result_limit = count that can take max 200 (mine_user_tweets) and max 100 (search_tweets)\"\"\"\n",
    "        \n",
    "        self.api = api        \n",
    "        self.result_limit = result_limit\n",
    "        self.max_pages = max_pages\n",
    "        \n",
    "\n",
    "    def mine_user_tweets(self, user, mine_retweets=False):\n",
    "        \"\"\" Mine tweets of user = screen_name or user_id\"\"\"\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= self.max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, max_id=last_tweet_id - 1, \n",
    "                                                        include_rts=mine_retweets)\n",
    "                statuses = [ _.AsDict() for _ in statuses]\n",
    "            else:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, include_rts=mine_retweets)\n",
    "                statuses = [_.AsDict() for _ in statuses]\n",
    "                \n",
    "            for item in statuses:\n",
    "                # Using try except here.\n",
    "                # When retweets = 0 we get an error (GetUserTimeline fails to create a key, 'retweet_count')\n",
    "                try:\n",
    "                    mined = {\n",
    "                        'mined_at':         datetime.datetime.now(),\n",
    "                        'created_at':       item['created_at'],\n",
    "                        'tweet_id':         item['id'],\n",
    "                        'tweet_id_str':     item['id_str'],\n",
    "                        'screen_name':      item['user']['screen_name'],\n",
    "                        'favorite_count':   item['favorite_count'],\n",
    "                        'text':             item['full_text'],\n",
    "                        'source':           item['source'],\n",
    "                        'language':         item['lang'],\n",
    "                        'retweet_count':    item['retweet_count'],\n",
    "                        'user_favourites_count': item['user']['favourites_count'],\n",
    "                        'followers_count':  item['user']['followers_count'],\n",
    "                        'friends_count':    item['user']['friends_count']\n",
    "                    }\n",
    "            \n",
    "                \n",
    "                except:\n",
    "                    mined = {\n",
    "                        'mined_at':         datetime.datetime.now(),\n",
    "                        'created_at':       item['created_at'],\n",
    "                        'tweet_id':         item['id'],\n",
    "                        'tweet_id_str':     item['id_str'],\n",
    "                        'screen_name':      item['user']['screen_name'],\n",
    "                        'favorite_count':   item['favorite_count'],\n",
    "                        'text':             item['full_text'],\n",
    "                        'source':           item['source'],\n",
    "                        'language':         item['lang'],\n",
    "                        'retweet_count':    0,\n",
    "                        'user_favourites_count': item['user']['favourites_count'],\n",
    "                        'followers_count':  item['user']['followers_count'],\n",
    "                        'friends_count':    item['user']['friends_count']\n",
    "                        }\n",
    "                \n",
    "                last_tweet_id = item['id']\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def search_tweets(max_pages = 20, count = 20, raw_query = None, result_type = 'mixed'):\n",
    "        \"\"\" Search tweets \"\"\"\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses = api.GetSearch(raw_query=raw_query, count = count, result_type=result_type, max_id=last_tweet_id - 1)\n",
    "                statuses = [ _.AsDict() for _ in statuses]\n",
    "            else:\n",
    "                statuses = api.GetSearch(raw_query=raw_query, count = count, result_type=result_type)\n",
    "                statuses = [_.AsDict() for _ in statuses]\n",
    "                \n",
    "            for item in statuses:\n",
    "                # Using try except here.\n",
    "                # When retweets = 0 we get an error (GetUserTimeline fails to create a key, 'retweet_count')\n",
    "                try:\n",
    "                    mined = {\n",
    "                        'mined_at':                datetime.datetime.now(),\n",
    "                        'created_at':              item['created_at'],\n",
    "                        'tweet_id':                item['id'],\n",
    "                        'tweet_id_str':            item['id_str'],\n",
    "                        'in_reply_to_screen_name': item['in_reply_to_screen_name'],\n",
    "                        'in_reply_to_status_id':   item['in_reply_to_status_id'],\n",
    "                        'in_reply_to_user_id':     item['in_reply_to_user_id'],\n",
    "                        'language':                item['lang'],\n",
    "                        'text':                    item['full_text'],\n",
    "                        'hashtags':                item['hashtags'],\n",
    "                        'source':                  item['source'],\n",
    "                       # info about user\n",
    "                        'screen_name':             item['user']['screen_name'],\n",
    "                        'user_tweet_id':           item['user']['id'],\n",
    "                        'user_tweet_id_str':       item['user']['id_str'],\n",
    "                        'user_favourites_count':   item['user']['favourites_count'],\n",
    "                        'followers_count':         item['user']['followers_count'],\n",
    "                        'friends_count':           item['user']['friends_count']\n",
    "                    }\n",
    "                    \n",
    "                except:\n",
    "                    mined = {\n",
    "                        'mined_at':                datetime.datetime.now(),\n",
    "                        'created_at':              item['created_at'],\n",
    "                        'tweet_id':                item['id'],\n",
    "                        'tweet_id_str':            item['id_str'],\n",
    "#                         'in_reply_to_screen_name': item['in_reply_to_screen_name'],\n",
    "#                         'in_reply_to_status_id':   item['in_reply_to_status_id'],\n",
    "#                         'in_reply_to_user_id':     item['in_reply_to_user_id'],\n",
    "                        'language':                item['lang'],\n",
    "                        'text':                    item['full_text'],\n",
    "                        'hashtags':                item['hashtags'],\n",
    "                        'source':                  item['source'],\n",
    "                       # info about user\n",
    "                        'screen_name':             item['user']['screen_name'],\n",
    "                        'user_tweet_id':           item['user']['id'],\n",
    "                        'user_tweet_id_str':       item['user']['id_str'],\n",
    "                        'user_favourites_count':   item['user']['favourites_count'],\n",
    "                        'followers_count':         item['user']['followers_count'],\n",
    "                        'friends_count':           item['user']['friends_count']\n",
    "                    }\n",
    "                                            \n",
    "                \n",
    "                last_tweet_id = item['id']\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T07:34:34.346271Z",
     "start_time": "2019-05-06T07:34:34.330962Z"
    }
   },
   "outputs": [],
   "source": [
    "def processing_and_saving(df, file_name, mine_user_twitter=1):\n",
    "    \"\"\" Save retrieved tweets in csv file.\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    df : dataframe of tweets'data\n",
    "    file_name: name with which the csv will be saved (without extension)\n",
    "    mine_user_twitter: Indicates if df came contains tweets from a twitter user, i.e., was obtained using \n",
    "    GetUserTimeline since the information obtained from this method is different from an API search from GetSearch\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    TodaysDate = time.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "    \n",
    "    # Create columns 'year', 'month', 'day', 'hour', 'min' from 'created_at'\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "        \n",
    "    df['year'] = df['created_at'].dt.year \n",
    "    df['month'] = df['created_at'].dt.month \n",
    "    df['day'] = df['created_at'].dt.day \n",
    "    df['hour'] = df['created_at'].dt.hour \n",
    "    df['minute'] = df['created_at'].dt.minute\n",
    "    df['day_of_week'] = df['created_at'].dt.weekday\n",
    "    \n",
    "    if mine_user_twitter:\n",
    "    \n",
    "        df = df[['mined_at', 'screen_name', 'tweet_id', 'tweet_id_str', 'created_at', 'year', 'month', 'day','day_of_week', \n",
    "             'hour', 'minute', 'retweet_count', 'favorite_count', 'source', 'language', 'user_favourites_count', \n",
    "             'followers_count','friends_count','text']]\n",
    "    else:\n",
    "        df = df[['mined_at', 'tweet_id', 'tweet_id_str', 'in_reply_to_screen_name','in_reply_to_status_id',\n",
    "                 'in_reply_to_user_id', 'hashtags','source','language', 'created_at', 'year', 'month', 'day','day_of_week', \n",
    "                 'hour', 'minute','screen_name','user_tweet_id','user_tweet_id_str','user_favourites_count','followers_count',\n",
    "                 'friends_count', 'text']]\n",
    "        \n",
    "    df.sort_values(by='created_at',inplace = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    df.to_csv(\"../data/tweets/\"+file_name+\"_\"+TodaysDate+\".csv\", index = False)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting twitter by user\n",
    "\n",
    "The goal of this project is to check the sentiment of users towards the main providers of online grocery shopping, i.e., Jumbo Supermarkten, AH, and Picnic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the class\n",
    "---\n",
    "\n",
    "Make sure you pass the keys dictionary and the api as arguments.\n",
    "\n",
    "**Check:** call the object's `mine_user_tweets()` method, providing a user to pull the tweets of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T07:34:35.015063Z",
     "start_time": "2019-05-06T07:34:35.009990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=20, max_pages = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jairbolsonaro = miner.mine_user_tweets(user=\"jairbolsonaro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. Recursos liberados para atender estados da Amazônia Legal, desde compra de máquinas até construções de vias para facilitação de locomoção da população;\n",
      "\n",
      "9. A superintendência do Desenvolvimento do Centro-Oeste garantiu recursos para melhorar a infraestrutura de cidades goianas\n",
      "--\n",
      "6. Entregues 349 moradias em Goiás e Pará, focando na dignidade das pessoas mais humildes;\n",
      "\n",
      "7. Em Minas Gerais, o @mdregional_br liberou recursos para ampliação da produção irrigada no Norte e Nordeste do estado;\n",
      "--\n",
      "4. O @mdregional_br também selecionou 6 projetos para melhorar e ampliar os sistemas de abastecimento de água e saneamento básico em São Paulo;\n",
      "\n",
      "5. Foi autorizada a retomada de obras de 730 moradias em Suzano (SP) e Tabatinga (AM), gerando mais 2,6 mil empregos nos locais;\n",
      "--\n",
      "2. Em São Vicente-SP repasse de verbas para reconstrução da ponte A Tribuna;\n",
      "\n",
      "3. Na cidade de São Bernardo do Campo-SP,  as obras de contenção de encostas e entregas de mais unidades habitacionais e andamento de mais ações no mesmo sentido no Parque Jardim Ipê; @rogeriosmarinho\n",
      "--\n",
      "MAIS ALGUMAS AÇÕES DO GOVERNO DO BRASIL ENTRE OS DIAS 15 E 19 DE JUNHO: \n",
      "\n",
      "- Mais informações sobre divulgações diárias do trabalho do @govbr , acompanhe as redes sociais.\n",
      "\n",
      "1. O @mdregional_br entregou mais 300 moradias em Osasco-SP;\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "for x in range(5):\n",
    "    print(jairbolsonaro[x]['text'])\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro = processing_and_saving(pd.DataFrame(jairbolsonaro), 'jairbolsonaro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mined_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-20 23:24:33.771297</td>\n",
       "      <td>jairbolsonaro</td>\n",
       "      <td>1116868726866042881</td>\n",
       "      <td>1116868726866042881</td>\n",
       "      <td>2019-04-13 01:00:29+00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3215</td>\n",
       "      <td>27779</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>pt</td>\n",
       "      <td>2758</td>\n",
       "      <td>6667529</td>\n",
       "      <td>515</td>\n",
       "      <td>Nossa política é de mercado aberto e de não in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-20 23:24:33.771297</td>\n",
       "      <td>jairbolsonaro</td>\n",
       "      <td>1116869473787625472</td>\n",
       "      <td>1116869473787625472</td>\n",
       "      <td>2019-04-13 01:03:27+00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3114</td>\n",
       "      <td>24198</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>und</td>\n",
       "      <td>2758</td>\n",
       "      <td>6667529</td>\n",
       "      <td>515</td>\n",
       "      <td>https://t.co/olbvIPqajX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-20 23:24:33.771297</td>\n",
       "      <td>jairbolsonaro</td>\n",
       "      <td>1117021839123988482</td>\n",
       "      <td>1117021839123988482</td>\n",
       "      <td>2019-04-13 11:08:54+00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3462</td>\n",
       "      <td>21712</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>pt</td>\n",
       "      <td>2758</td>\n",
       "      <td>6667529</td>\n",
       "      <td>515</td>\n",
       "      <td>A Embrapa, em parceria com a Funai e outros ór...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-20 23:24:33.771297</td>\n",
       "      <td>jairbolsonaro</td>\n",
       "      <td>1117070706712379392</td>\n",
       "      <td>1117070706712379392</td>\n",
       "      <td>2019-04-13 14:23:05+00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>3119</td>\n",
       "      <td>30028</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>und</td>\n",
       "      <td>2758</td>\n",
       "      <td>6667529</td>\n",
       "      <td>515</td>\n",
       "      <td>🇧🇷👍🏻👉🏻👉🏻 https://t.co/uvoY9JSG6I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-20 23:24:33.771297</td>\n",
       "      <td>jairbolsonaro</td>\n",
       "      <td>1117086242502598661</td>\n",
       "      <td>1117086242502598661</td>\n",
       "      <td>2019-04-13 15:24:49+00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>4972</td>\n",
       "      <td>30649</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>pt</td>\n",
       "      <td>2758</td>\n",
       "      <td>6667529</td>\n",
       "      <td>515</td>\n",
       "      <td>O Governo Federal trabalhando para concluir ro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mined_at    screen_name             tweet_id  \\\n",
       "0 2020-06-20 23:24:33.771297  jairbolsonaro  1116868726866042881   \n",
       "1 2020-06-20 23:24:33.771297  jairbolsonaro  1116869473787625472   \n",
       "2 2020-06-20 23:24:33.771297  jairbolsonaro  1117021839123988482   \n",
       "3 2020-06-20 23:24:33.771297  jairbolsonaro  1117070706712379392   \n",
       "4 2020-06-20 23:24:33.771297  jairbolsonaro  1117086242502598661   \n",
       "\n",
       "          tweet_id_str                created_at  year  month  day  \\\n",
       "0  1116868726866042881 2019-04-13 01:00:29+00:00  2019      4   13   \n",
       "1  1116869473787625472 2019-04-13 01:03:27+00:00  2019      4   13   \n",
       "2  1117021839123988482 2019-04-13 11:08:54+00:00  2019      4   13   \n",
       "3  1117070706712379392 2019-04-13 14:23:05+00:00  2019      4   13   \n",
       "4  1117086242502598661 2019-04-13 15:24:49+00:00  2019      4   13   \n",
       "\n",
       "   day_of_week  hour  minute  retweet_count  favorite_count  \\\n",
       "0            5     1       0           3215           27779   \n",
       "1            5     1       3           3114           24198   \n",
       "2            5    11       8           3462           21712   \n",
       "3            5    14      23           3119           30028   \n",
       "4            5    15      24           4972           30649   \n",
       "\n",
       "                                              source language  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...       pt   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...      und   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...       pt   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...      und   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...       pt   \n",
       "\n",
       "   user_favourites_count  followers_count  friends_count  \\\n",
       "0                   2758          6667529            515   \n",
       "1                   2758          6667529            515   \n",
       "2                   2758          6667529            515   \n",
       "3                   2758          6667529            515   \n",
       "4                   2758          6667529            515   \n",
       "\n",
       "                                                text  \n",
       "0  Nossa política é de mercado aberto e de não in...  \n",
       "1                            https://t.co/olbvIPqajX  \n",
       "2  A Embrapa, em parceria com a Funai e outros ór...  \n",
       "3                   🇧🇷👍🏻👉🏻👉🏻 https://t.co/uvoY9JSG6I  \n",
       "4  O Governo Federal trabalhando para concluir ro...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bolsonaro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2996 entries, 0 to 2995\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype              \n",
      "---  ------                 --------------  -----              \n",
      " 0   mined_at               2996 non-null   datetime64[ns]     \n",
      " 1   screen_name            2996 non-null   object             \n",
      " 2   tweet_id               2996 non-null   int64              \n",
      " 3   tweet_id_str           2996 non-null   object             \n",
      " 4   created_at             2996 non-null   datetime64[ns, UTC]\n",
      " 5   year                   2996 non-null   int64              \n",
      " 6   month                  2996 non-null   int64              \n",
      " 7   day                    2996 non-null   int64              \n",
      " 8   day_of_week            2996 non-null   int64              \n",
      " 9   hour                   2996 non-null   int64              \n",
      " 10  minute                 2996 non-null   int64              \n",
      " 11  retweet_count          2996 non-null   int64              \n",
      " 12  favorite_count         2996 non-null   int64              \n",
      " 13  source                 2996 non-null   object             \n",
      " 14  language               2996 non-null   object             \n",
      " 15  user_favourites_count  2996 non-null   int64              \n",
      " 16  followers_count        2996 non-null   int64              \n",
      " 17  friends_count          2996 non-null   int64              \n",
      " 18  text                   2996 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), int64(12), object(5)\n",
      "memory usage: 444.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bolsonaro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-04-13 01:00:29+0000', tz='UTC'),\n",
       " Timestamp('2020-06-20 19:46:37+0000', tz='UTC'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_bolsonaro.created_at),max(df_bolsonaro.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying GetSearch to search for a defined query\n",
    "\n",
    "Making a search in Twitter using `@jairbolsonaro covid-19 corona` gave us `q=%40jairbolsonaro%20covid-19%20corona&src=typed_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_query=\"q=%40jairbolsonaro%20covid-19%20corona&src=typed_query\"\n",
    "search_bolsonaro_covid = TweetMiner.search_tweets(max_pages = 15, count = 20, raw_query = raw_query, result_type = 'mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_bolsonaro_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mined_at': datetime.datetime(2020, 6, 20, 23, 28, 8, 65310),\n",
       " 'created_at': 'Sat Jun 20 20:26:50 +0000 2020',\n",
       " 'tweet_id': 1274438583731064835,\n",
       " 'tweet_id_str': '1274438583731064835',\n",
       " 'in_reply_to_screen_name': 'secomvc',\n",
       " 'in_reply_to_status_id': 1274416731453259779,\n",
       " 'in_reply_to_user_id': 1158389772920020993,\n",
       " 'language': 'pt',\n",
       " 'text': '@secomvc @jairbolsonaro @minsaude @funaioficial @DefesaGovBr @anvisa_oficial @MinEconomia É urgente q o Ministério da Saúde cumpra sua função de liderar a crise do Corona\\nEle tem q FALAR c/ a população, unir estados e municípios p/ q juntos evitem a disseminação\\nEsse 👇 é um triste exemplo de q as pessoas NÃO podem ficar doentes AO MESMO TEMPO\\n\\nhttps://t.co/TCaK16LAEB',\n",
       " 'hashtags': [],\n",
       " 'source': '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>',\n",
       " 'screen_name': 'SandraMTRibeir1',\n",
       " 'user_tweet_id': 1101575981356236803,\n",
       " 'user_tweet_id_str': '1101575981356236803',\n",
       " 'user_favourites_count': 1455,\n",
       " 'followers_count': 20,\n",
       " 'friends_count': 342}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_bolsonaro_covid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_bolsonaro_corona = processing_and_saving(pd.DataFrame(search_bolsonaro_covid),\"search_bolsonaro_corona\",mine_user_twitter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mined_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>created_at</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_tweet_id</th>\n",
       "      <th>user_tweet_id_str</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2020-06-20 23:28:08.696027</td>\n",
       "      <td>1274438583731064835</td>\n",
       "      <td>1274438583731064835</td>\n",
       "      <td>secomvc</td>\n",
       "      <td>1.274417e+18</td>\n",
       "      <td>1.158390e+18</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>2020-06-20 20:26:50+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>SandraMTRibeir1</td>\n",
       "      <td>1101575981356236803</td>\n",
       "      <td>1101575981356236803</td>\n",
       "      <td>1455</td>\n",
       "      <td>20</td>\n",
       "      <td>342</td>\n",
       "      <td>@secomvc @jairbolsonaro @minsaude @funaioficia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2020-06-20 23:28:11.781770</td>\n",
       "      <td>1274438583731064835</td>\n",
       "      <td>1274438583731064835</td>\n",
       "      <td>secomvc</td>\n",
       "      <td>1.274417e+18</td>\n",
       "      <td>1.158390e+18</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>2020-06-20 20:26:50+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>SandraMTRibeir1</td>\n",
       "      <td>1101575981356236803</td>\n",
       "      <td>1101575981356236803</td>\n",
       "      <td>1455</td>\n",
       "      <td>20</td>\n",
       "      <td>342</td>\n",
       "      <td>@secomvc @jairbolsonaro @minsaude @funaioficia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2020-06-20 23:28:09.875278</td>\n",
       "      <td>1274438583731064835</td>\n",
       "      <td>1274438583731064835</td>\n",
       "      <td>secomvc</td>\n",
       "      <td>1.274417e+18</td>\n",
       "      <td>1.158390e+18</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>2020-06-20 20:26:50+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>SandraMTRibeir1</td>\n",
       "      <td>1101575981356236803</td>\n",
       "      <td>1101575981356236803</td>\n",
       "      <td>1455</td>\n",
       "      <td>20</td>\n",
       "      <td>342</td>\n",
       "      <td>@secomvc @jairbolsonaro @minsaude @funaioficia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2020-06-20 23:28:11.514203</td>\n",
       "      <td>1274438583731064835</td>\n",
       "      <td>1274438583731064835</td>\n",
       "      <td>secomvc</td>\n",
       "      <td>1.274417e+18</td>\n",
       "      <td>1.158390e+18</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>2020-06-20 20:26:50+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>SandraMTRibeir1</td>\n",
       "      <td>1101575981356236803</td>\n",
       "      <td>1101575981356236803</td>\n",
       "      <td>1455</td>\n",
       "      <td>20</td>\n",
       "      <td>342</td>\n",
       "      <td>@secomvc @jairbolsonaro @minsaude @funaioficia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2020-06-20 23:28:08.065310</td>\n",
       "      <td>1274438583731064835</td>\n",
       "      <td>1274438583731064835</td>\n",
       "      <td>secomvc</td>\n",
       "      <td>1.274417e+18</td>\n",
       "      <td>1.158390e+18</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>2020-06-20 20:26:50+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>SandraMTRibeir1</td>\n",
       "      <td>1101575981356236803</td>\n",
       "      <td>1101575981356236803</td>\n",
       "      <td>1455</td>\n",
       "      <td>20</td>\n",
       "      <td>342</td>\n",
       "      <td>@secomvc @jairbolsonaro @minsaude @funaioficia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mined_at             tweet_id         tweet_id_str  \\\n",
       "220 2020-06-20 23:28:08.696027  1274438583731064835  1274438583731064835   \n",
       "221 2020-06-20 23:28:11.781770  1274438583731064835  1274438583731064835   \n",
       "222 2020-06-20 23:28:09.875278  1274438583731064835  1274438583731064835   \n",
       "223 2020-06-20 23:28:11.514203  1274438583731064835  1274438583731064835   \n",
       "224 2020-06-20 23:28:08.065310  1274438583731064835  1274438583731064835   \n",
       "\n",
       "    in_reply_to_screen_name  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "220                 secomvc           1.274417e+18         1.158390e+18   \n",
       "221                 secomvc           1.274417e+18         1.158390e+18   \n",
       "222                 secomvc           1.274417e+18         1.158390e+18   \n",
       "223                 secomvc           1.274417e+18         1.158390e+18   \n",
       "224                 secomvc           1.274417e+18         1.158390e+18   \n",
       "\n",
       "    hashtags                                             source language  \\\n",
       "220       []  <a href=\"http://twitter.com/#!/download/ipad\" ...       pt   \n",
       "221       []  <a href=\"http://twitter.com/#!/download/ipad\" ...       pt   \n",
       "222       []  <a href=\"http://twitter.com/#!/download/ipad\" ...       pt   \n",
       "223       []  <a href=\"http://twitter.com/#!/download/ipad\" ...       pt   \n",
       "224       []  <a href=\"http://twitter.com/#!/download/ipad\" ...       pt   \n",
       "\n",
       "                   created_at  ...  day_of_week  hour  minute  \\\n",
       "220 2020-06-20 20:26:50+00:00  ...            5    20      26   \n",
       "221 2020-06-20 20:26:50+00:00  ...            5    20      26   \n",
       "222 2020-06-20 20:26:50+00:00  ...            5    20      26   \n",
       "223 2020-06-20 20:26:50+00:00  ...            5    20      26   \n",
       "224 2020-06-20 20:26:50+00:00  ...            5    20      26   \n",
       "\n",
       "         screen_name        user_tweet_id    user_tweet_id_str  \\\n",
       "220  SandraMTRibeir1  1101575981356236803  1101575981356236803   \n",
       "221  SandraMTRibeir1  1101575981356236803  1101575981356236803   \n",
       "222  SandraMTRibeir1  1101575981356236803  1101575981356236803   \n",
       "223  SandraMTRibeir1  1101575981356236803  1101575981356236803   \n",
       "224  SandraMTRibeir1  1101575981356236803  1101575981356236803   \n",
       "\n",
       "    user_favourites_count  followers_count friends_count  \\\n",
       "220                  1455               20           342   \n",
       "221                  1455               20           342   \n",
       "222                  1455               20           342   \n",
       "223                  1455               20           342   \n",
       "224                  1455               20           342   \n",
       "\n",
       "                                                  text  \n",
       "220  @secomvc @jairbolsonaro @minsaude @funaioficia...  \n",
       "221  @secomvc @jairbolsonaro @minsaude @funaioficia...  \n",
       "222  @secomvc @jairbolsonaro @minsaude @funaioficia...  \n",
       "223  @secomvc @jairbolsonaro @minsaude @funaioficia...  \n",
       "224  @secomvc @jairbolsonaro @minsaude @funaioficia...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_bolsonaro_corona.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 23 columns):\n",
      " #   Column                   Non-Null Count  Dtype              \n",
      "---  ------                   --------------  -----              \n",
      " 0   mined_at                 225 non-null    datetime64[ns]     \n",
      " 1   tweet_id                 225 non-null    int64              \n",
      " 2   tweet_id_str             225 non-null    object             \n",
      " 3   in_reply_to_screen_name  90 non-null     object             \n",
      " 4   in_reply_to_status_id    90 non-null     float64            \n",
      " 5   in_reply_to_user_id      90 non-null     float64            \n",
      " 6   hashtags                 225 non-null    object             \n",
      " 7   source                   225 non-null    object             \n",
      " 8   language                 225 non-null    object             \n",
      " 9   created_at               225 non-null    datetime64[ns, UTC]\n",
      " 10  year                     225 non-null    int64              \n",
      " 11  month                    225 non-null    int64              \n",
      " 12  day                      225 non-null    int64              \n",
      " 13  day_of_week              225 non-null    int64              \n",
      " 14  hour                     225 non-null    int64              \n",
      " 15  minute                   225 non-null    int64              \n",
      " 16  screen_name              225 non-null    object             \n",
      " 17  user_tweet_id            225 non-null    int64              \n",
      " 18  user_tweet_id_str        225 non-null    object             \n",
      " 19  user_favourites_count    225 non-null    int64              \n",
      " 20  followers_count          225 non-null    int64              \n",
      " 21  friends_count            225 non-null    int64              \n",
      " 22  text                     225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), float64(2), int64(11), object(8)\n",
      "memory usage: 40.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_search_bolsonaro_corona.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFS:\n",
    "\n",
    "> https://python-twitter.readthedocs.io/en/latest/index.html\n",
    "\n",
    "> https://developer.twitter.com/en/docs\n",
    "\n",
    "Info:\n",
    "\n",
    "1st corona case in The Netherlands: 27/02/2020\n",
    "\n",
    "1st corona case in Brazil: 26/02/2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "- Check functions to see if I have all I need.\n",
    "- Generalize as much as possible\n",
    "- Order infor per date (created_at?)\n",
    "- Should I have a function also for search?\n",
    "- Retrieve info for:\n",
    "    - jairbolsonaro\n",
    "    - picnic\n",
    "    - JumboSupermarkt\n",
    "    - albertheijn\n",
    "    - evanescence\n",
    "    - WTofficial\n",
    "    \n",
    "- Include in class `TweetMiner` a function to user `GetSearch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [`python-twitter`](https://python-twitter.readthedocs.io/en/latest/getting_started.html) since I've been facing some time out problems with [`Tweepy`](http://docs.tweepy.org/en/latest/getting_started.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install python-twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up twitter authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "Function `mine_user_tweets` made use of [Get user_timeline](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T07:34:34.325020Z",
     "start_time": "2019-05-06T07:34:34.299182Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "#TweetMiner function from Mike Roman\n",
    "\n",
    "# some modification added by me - 15/04/19\n",
    "\n",
    "class TweetMiner(object):\n",
    "\n",
    "    \n",
    "    def __init__(self, api, result_limit = 20, max_pages = 40):\n",
    "        \"\"\"result_limit = count that can take max 200\"\"\"\n",
    "        \n",
    "        self.api = api        \n",
    "        self.result_limit = result_limit\n",
    "        self.max_pages = max_pages\n",
    "        \n",
    "\n",
    "    def mine_user_tweets(self, user, mine_retweets=False):\n",
    "        \"\"\" Mine tweets of user = screen_name or user_id\"\"\"\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= self.max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, max_id=last_tweet_id - 1, \n",
    "                                                        include_rts=mine_retweets)\n",
    "                statuses = [ _.AsDict() for _ in statuses]\n",
    "            else:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, include_rts=mine_retweets)\n",
    "                statuses = [_.AsDict() for _ in statuses]\n",
    "                \n",
    "            for item in statuses:\n",
    "                # Using try except here.\n",
    "                # When retweets = 0 we get an error (GetUserTimeline fails to create a key, 'retweet_count')\n",
    "                try:\n",
    "                    mined = {\n",
    "                        'tweet_id':        item['id'],\n",
    "                        'handle':          item['user']['screen_name'],\n",
    "                        'retweet_count':   item['retweet_count'],\n",
    "                        'text':            item['full_text'],\n",
    "                        'mined_at':        datetime.datetime.now(),\n",
    "                        'created_at':      item['created_at'],\n",
    "                        'favorite_count':  item['favorite_count'],\n",
    "                        'tweet_id_str':    item['id_str'],\n",
    "                        'source':          item['source'],\n",
    "                        \n",
    "                    }\n",
    "                    \n",
    "            \n",
    "                \n",
    "                except:\n",
    "                        mined = {\n",
    "                        'tweet_id':        item['id'],\n",
    "                        'handle':          item['user']['screen_name'],\n",
    "                        'retweet_count':   0,\n",
    "                        'text':            item['full_text'],\n",
    "                        'mined_at':        datetime.datetime.now(),\n",
    "                        'created_at':      item['created_at'],\n",
    "#                         'favorite_count':  item['favorite_count'],\n",
    "                        'tweet_id_str':    item['id_str'],\n",
    "                        'source':          item['source'],\n",
    "                    }\n",
    "                \n",
    "                last_tweet_id = item['id']\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T07:34:34.346271Z",
     "start_time": "2019-05-06T07:34:34.330962Z"
    }
   },
   "outputs": [],
   "source": [
    "def processing_and_saving(df, file_name):\n",
    "    \n",
    "    TodaysDate = time.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "    \n",
    "    # Create columns 'year', 'month', 'day', 'hour', 'min' from 'created_at'\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "        \n",
    "    df['year'] = df['created_at'].dt.year \n",
    "    df['month'] = df['created_at'].dt.month \n",
    "    df['day'] = df['created_at'].dt.day \n",
    "    df['hour'] = df['created_at'].dt.hour \n",
    "    df['minute'] = df['created_at'].dt.minute\n",
    "    df['day_of_week'] = df['created_at'].dt.weekday\n",
    "    \n",
    "    df.sort_values(by='created_at',inplace = True)\n",
    "    \n",
    "    df = df[['mined_at', 'handle','tweet_id', 'tweet_id_str','created_at', \n",
    "             'year', 'month', 'day','day_of_week', 'hour', 'minute','retweet_count', 'source', 'text']]\n",
    "    \n",
    "    df.to_csv(\"./data_tweets/\"+file_name+\"_\"+TodaysDate+\".csv\", index = False)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting twitter by user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the class\n",
    "---\n",
    "\n",
    "Make sure you pass the keys dictionary and the api as arguments.\n",
    "\n",
    "**Check:** call the object's `mine_user_tweets()` method, providing a user to pull the tweets of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T07:34:35.015063Z",
     "start_time": "2019-05-06T07:34:35.009990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=20, max_pages = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jairbolsonaro = miner.mine_user_tweets(user=\"jairbolsonaro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(5):\n",
    "    print(jairbolsonaro[x]['text'])\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the tweet ouputs to a pandas DataFrame\n",
    "### jairbolsonaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jairbolsonaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro = processing_and_saving(pd.DataFrame(jairbolsonaro), 'jairbolsonaro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df_bolsonaro.created_at),max(df_bolsonaro.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro.sort_values(by='created_at')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### picnic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=20, max_pages = 100)\n",
    "picnic = miner.mine_user_tweets(user=\"picnic\")\n",
    "df_picnic = processing_and_saving(pd.DataFrame(picnic), \"picnic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_picnic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df_picnic.created_at),max(df_picnic.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JumboSupermarkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=20, max_pages = 200)\n",
    "JumboSupermarkt = miner.mine_user_tweets(user=\"JumboSupermarkt\")\n",
    "df_JumboSupermarkt = processing_and_saving(pd.DataFrame(JumboSupermarkt), \"JumboSupermarkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JumboSupermarkt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df_JumboSupermarkt.created_at),max(df_JumboSupermarkt.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albertheijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=20, max_pages = 300)\n",
    "albertheijn = miner.mine_user_tweets(user=\"albertheijn\")\n",
    "df_albertheijn = processing_and_saving(pd.DataFrame(albertheijn), \"albertheijn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albertheijn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df_albertheijn.created_at),max(df_albertheijn.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evanescence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=20, max_pages = 300)\n",
    "evanescence = miner.mine_user_tweets(user=\"evanescence\")\n",
    "df_evanescence = processing_and_saving(pd.DataFrame(evanescence), \"evanescence\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evanescence.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min(df_evanescence.created_at),max(df_evanescence.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evanescence.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within Temptation - WTofficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result limit == count parameter from our GetUserTimeline() it can take max 200\n",
    "# More pages more back in time you can go\n",
    "miner = TweetMiner(api, result_limit=20, max_pages = 300)\n",
    "WTofficial = miner.mine_user_tweets(user=\"WTofficial\")\n",
    "df_WTofficial = processing_and_saving(pd.DataFrame(WTofficial), \"WTofficial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WTofficial.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df_WTofficial.created_at),max(df_WTofficial.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with GetSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tweets(max_pages = 20, count = 20, raw_query = None, result_type = 'mixed'):\n",
    "        \"\"\" Search tweets \"\"\"\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses = api.GetSearch(raw_query=raw_query, count = count, result_type=result_type, max_id=last_tweet_id - 1)\n",
    "                statuses = [ _.AsDict() for _ in statuses]\n",
    "            else:\n",
    "                statuses = api.GetSearch(raw_query=raw_query, count = count, result_type=result_type)\n",
    "                statuses = [_.AsDict() for _ in statuses]\n",
    "                \n",
    "            for item in statuses:\n",
    "                # Using try except here.\n",
    "                # When retweets = 0 we get an error (GetUserTimeline fails to create a key, 'retweet_count')\n",
    "                try:\n",
    "                    mined = {\n",
    "                        'tweet_id':        item['id'],\n",
    "                        'handle':          item['user']['screen_name'],\n",
    "                        'retweet_count':   item['retweet_count'],\n",
    "                        'text':            item['full_text'],\n",
    "                        'mined_at':        datetime.datetime.now(),\n",
    "                        'created_at':      item['created_at'],\n",
    "                        'favorite_count':  item['favorite_count'],\n",
    "                        'tweet_id_str':    item['id_str'],\n",
    "                        'source':          item['source'],\n",
    "                        \n",
    "                    }\n",
    "                    \n",
    "            \n",
    "                \n",
    "                except:\n",
    "                        mined = {\n",
    "                        'tweet_id':        item['id'],\n",
    "                        'handle':          item['user']['screen_name'],\n",
    "                        'retweet_count':   0,\n",
    "                        'text':            item['full_text'],\n",
    "                        'mined_at':        datetime.datetime.now(),\n",
    "                        'created_at':      item['created_at'],\n",
    "#                         'favorite_count':  item['favorite_count'],\n",
    "                        'tweet_id_str':    item['id_str'],\n",
    "                        'source':          item['source'],\n",
    "                    }\n",
    "                \n",
    "                last_tweet_id = item['id']\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_query=\"q=jairbolsonaro%2C%20corona%2C%20covid&src=typed_query\"\n",
    "results = search_tweets(max_pages = 15, count = 20, raw_query = raw_query, result_type = 'mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_bolsonaro_corona = processing_and_saving(pd.DataFrame(results),\"search_bolsonaro_corona\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_bolsonaro_corona.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_bolsonaro_corona.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = api.GetSearch(raw_query=\"q=picnic\", count = 100, result_type='popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_query = \"q=picnic%20jumbo%20ah%20delivery&src=typed_query\"\n",
    "\n",
    "picnic_ah_jumbo_search = search_tweets(max_pages = 1, count = 5, raw_query = raw_query, result_type = 'mixed')\n",
    "picnic_ah_jumbo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_picnic_ah_jumbo_search = processing_and_saving(pd.DataFrame(picnic_ah_jumbo_search),\"picnic_ah_jumbo_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_picnic_ah_jumbo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
